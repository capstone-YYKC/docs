# 240214

### dlib, OpenCV, python을 이용한 얼굴 랜드마크

모델 링크

[face-recognition.js-models/models/shape_predictor_5_face_landmarks.dat at master · justadudewhohacks/face-recognition.js-models (github.com)](https://github.com/justadudewhohacks/face-recognition.js-models/blob/master/models/shape_predictor_5_face_landmarks.dat)

코드 링크

[[OpenCV] dlib 이미지 얼굴 랜드마크 (face landmark)](https://prlabhotelshoe.tistory.com/4)

```python
import numpy as np
import dlib
import cv2

RIGHT_EYE = list(range(2, 4))
LEFT_EYE = list(range(0, 2))
ALL = list(range(0, 5))

predictor_file = './shape_predictor_5_face_landmarks.dat' 
image_file = './img.jpg'

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor(predictor_file)

image = cv2.imread(image_file)
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

rects = detector(gray, 1)
print("Number of faces detected: {}".format(len(rects)))

for (i, rect) in enumerate(rects):
    points = np.matrix([[p.x, p.y] for p in predictor(gray, rect).parts()])
    show_parts = points[ALL]
    for (i, point) in enumerate(show_parts):
        x = point[0,0]
        y = point[0,1]
        
        if(i in LEFT_EYE):
            print("LEFT EYE {} 좌표: x={}, y={}".format(i+1, x, y))

        if(i in RIGHT_EYE):
            print("RIGHT EYE {} 좌표: x={}, y={}".format(i+1, x, y))

        cv2.circle(image, (x, y), 1, (0, 0, 255), -1)
        cv2.putText(image, "{}".format(i + 1), (x, y - 2),
		cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0,255), 1)

cv2.imshow("Face Landmark", image)
cv2.waitKey(0)
```

이미 만들어진 모델을 가져다 쓴 것 이므로 기술적 심미성이 부족하다 판단될 경우 직접 모델을 학습하여 만들어야 될 수도 있음.

![240214_1](https://github.com/capstone-YYKC/docs/assets/109731614/3af61756-2860-47b6-abac-feaee459fcbc)

### 로봇 팔

3d모델링을 직접 하거나 3d모델링 사이트에서 구해서 3d프린터로 프레임을 출력해야 할듯.

- 구성

총 6개의 관절로 구성.

1번 관절: z축을 중심으로 회전하여 방향을 제어.

2번 관절: x축 또는 y축을 중심으로 회전하여 높이, 길이 제어

3번 관절: x축 또는 y축을 중심으로 회전하여 높이, 길이 제어

4번 관절: x축 또는 y축을 중심으로 회전하여 그리퍼의 수평 제어.

5번 관절: z축을 중심으로 360도 무한회전이 가능한 관절.(점안액 용기를 여닫기 위해.)

6번 관절: 점안액 용기를 집거나 놓을 수 있게 회전하는 관절.

- 제어 방식
    
    로봇팔의 그리퍼의 위치가 정해졌을때 이에 해당하는 관전들의 각도를 구하는 과정인 역기구학을 통해 계산.
    

### 동작 과정

1. 시작
2. 카메라를 통한 얼굴 이미지 캡쳐
3. 모델을 통한 눈의 좌표 계산
4. 로봇팔을 통해 점안액 용기 개방 후 눈의 좌표의 안약을 뿌려줌.
5. 두 눈에 모두 투여되면 용기를 다시 잠굼.
6. 종료

### 어플? 여러개의 안약?

이 작품의 핵심요소는 눈의 위치를 찾아 로봇팔이 자동으로 안약을 투여하는 것이 핵심이라 생각함.

어플이나, 여러개의 안약에 대해서는 구현할 때의 난이도가 너무 클 것으로 생각됨.

핵심요소만 구현하면 좋을듯.

### 필요한 재료들

1. 라즈베리파이
2. 모터, 모터 드라이버: 로봇팔 관절 제어를 위해 사용
3. 로봇팔 조립에 필요한 나사, 케이블 타이 점퍼 선 등.
4. 카메라 모듈: 얼굴 이미지를 캡쳐하여 눈의 좌표값을 추출하기 위해 사용.
5. 사람이 누울 수 있는 각도 조절이 가능한 침대(의자)